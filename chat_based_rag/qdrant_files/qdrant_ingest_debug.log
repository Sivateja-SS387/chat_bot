2025-02-06 15:07:53,617 - INFO - Use pytorch device_name: cpu
2025-02-06 15:07:53,618 - INFO - Load pretrained SentenceTransformer: BAAI/bge-large-en
2025-02-06 15:07:53,623 - DEBUG - Starting new HTTPS connection (1): huggingface.co:443
2025-02-06 15:07:54,008 - DEBUG - https://huggingface.co:443 "HEAD /BAAI/bge-large-en/resolve/main/modules.json HTTP/1.1" 200 0
2025-02-06 15:07:54,315 - DEBUG - https://huggingface.co:443 "HEAD /BAAI/bge-large-en/resolve/main/config_sentence_transformers.json HTTP/1.1" 200 0
2025-02-06 15:07:54,798 - DEBUG - https://huggingface.co:443 "HEAD /BAAI/bge-large-en/resolve/main/README.md HTTP/1.1" 200 0
2025-02-06 15:07:55,099 - DEBUG - https://huggingface.co:443 "HEAD /BAAI/bge-large-en/resolve/main/modules.json HTTP/1.1" 200 0
2025-02-06 15:07:55,370 - DEBUG - https://huggingface.co:443 "HEAD /BAAI/bge-large-en/resolve/main/sentence_bert_config.json HTTP/1.1" 200 0
2025-02-06 15:07:55,628 - DEBUG - https://huggingface.co:443 "HEAD /BAAI/bge-large-en/resolve/main/adapter_config.json HTTP/1.1" 404 0
2025-02-06 15:07:56,126 - DEBUG - https://huggingface.co:443 "HEAD /BAAI/bge-large-en/resolve/main/config.json HTTP/1.1" 200 0
2025-02-06 15:07:57,127 - DEBUG - https://huggingface.co:443 "HEAD /BAAI/bge-large-en/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2025-02-06 15:07:57,744 - DEBUG - https://huggingface.co:443 "GET /api/models/BAAI/bge-large-en/revision/main HTTP/1.1" 200 147009
2025-02-06 15:07:58,066 - DEBUG - https://huggingface.co:443 "GET /api/models/BAAI/bge-large-en HTTP/1.1" 200 147009
2025-02-06 15:08:02,939 - INFO - Embedding model initialized successfully
2025-02-06 15:08:02,940 - DEBUG - Test embedding dimension: 1024
2025-02-06 15:08:04,390 - DEBUG - connect_tcp.started host='localhost' port=6334 local_address=None timeout=5.0 socket_options=None
2025-02-06 15:08:04,393 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002D56C5E1910>
2025-02-06 15:08:04,394 - DEBUG - send_request_headers.started request=<Request [b'GET']>
2025-02-06 15:08:04,395 - DEBUG - send_request_headers.complete
2025-02-06 15:08:04,395 - DEBUG - send_request_body.started request=<Request [b'GET']>
2025-02-06 15:08:04,396 - DEBUG - send_request_body.complete
2025-02-06 15:08:04,396 - DEBUG - receive_response_headers.started request=<Request [b'GET']>
2025-02-06 15:08:04,404 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'zstd'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Thu, 06 Feb 2025 09:38:04 GMT')])
2025-02-06 15:08:04,405 - INFO - HTTP Request: GET http://localhost:6334/ "HTTP/1.1 200 OK"
2025-02-06 15:08:04,406 - DEBUG - receive_response_body.started request=<Request [b'GET']>
2025-02-06 15:08:04,407 - DEBUG - receive_response_body.complete
2025-02-06 15:08:04,408 - DEBUG - response_closed.started
2025-02-06 15:08:04,409 - DEBUG - response_closed.complete
2025-02-06 15:08:04,409 - DEBUG - close.started
2025-02-06 15:08:04,410 - DEBUG - close.complete
2025-02-06 15:08:04,410 - WARNING - Could not retrieve cluster info: 'QdrantClient' object has no attribute 'cluster_info'
2025-02-06 15:08:04,447 - INFO - Use pytorch device_name: cpu
2025-02-06 15:08:04,447 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-02-06 15:08:04,694 - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json HTTP/1.1" 200 0
2025-02-06 15:08:04,978 - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json HTTP/1.1" 200 0
2025-02-06 15:08:05,224 - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 200 0
2025-02-06 15:08:05,887 - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json HTTP/1.1" 200 0
2025-02-06 15:08:06,133 - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json HTTP/1.1" 200 0
2025-02-06 15:08:06,391 - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/adapter_config.json HTTP/1.1" 404 0
2025-02-06 15:08:06,640 - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 200 0
2025-02-06 15:08:07,000 - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2025-02-06 15:08:07,351 - DEBUG - https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/revision/main HTTP/1.1" 200 6820
2025-02-06 15:08:07,603 - DEBUG - https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2 HTTP/1.1" 200 6820
2025-02-06 15:08:51,408 - ERROR - Error creating ingestion log table: connection to server at "drug-data-analysis_a04f6f-postgres-1" (13.248.169.48), port 5432 failed: Connection timed out (0x0000274C/10060)
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "drug-data-analysis_a04f6f-postgres-1" (76.223.54.146), port 5432 failed: server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.

2025-02-06 15:08:51,410 - ERROR - Error during data ingestion: connection to server at "drug-data-analysis_a04f6f-postgres-1" (13.248.169.48), port 5432 failed: Connection timed out (0x0000274C/10060)
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "drug-data-analysis_a04f6f-postgres-1" (76.223.54.146), port 5432 failed: server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.

2025-02-06 15:09:37,325 - INFO - Use pytorch device_name: cpu
2025-02-06 15:09:37,326 - INFO - Load pretrained SentenceTransformer: BAAI/bge-large-en
2025-02-06 15:09:37,328 - DEBUG - Starting new HTTPS connection (1): huggingface.co:443
2025-02-06 15:09:37,671 - DEBUG - https://huggingface.co:443 "HEAD /BAAI/bge-large-en/resolve/main/modules.json HTTP/1.1" 200 0
2025-02-06 15:09:38,346 - DEBUG - https://huggingface.co:443 "HEAD /BAAI/bge-large-en/resolve/main/config_sentence_transformers.json HTTP/1.1" 200 0
2025-02-06 15:09:38,584 - DEBUG - https://huggingface.co:443 "HEAD /BAAI/bge-large-en/resolve/main/README.md HTTP/1.1" 200 0
2025-02-06 15:09:38,828 - DEBUG - https://huggingface.co:443 "HEAD /BAAI/bge-large-en/resolve/main/modules.json HTTP/1.1" 200 0
2025-02-06 15:09:39,499 - DEBUG - https://huggingface.co:443 "HEAD /BAAI/bge-large-en/resolve/main/sentence_bert_config.json HTTP/1.1" 200 0
2025-02-06 15:09:39,746 - DEBUG - https://huggingface.co:443 "HEAD /BAAI/bge-large-en/resolve/main/adapter_config.json HTTP/1.1" 404 0
2025-02-06 15:09:39,993 - DEBUG - https://huggingface.co:443 "HEAD /BAAI/bge-large-en/resolve/main/config.json HTTP/1.1" 200 0
2025-02-06 15:09:40,595 - DEBUG - https://huggingface.co:443 "HEAD /BAAI/bge-large-en/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2025-02-06 15:09:40,893 - DEBUG - https://huggingface.co:443 "GET /api/models/BAAI/bge-large-en/revision/main HTTP/1.1" 200 147009
2025-02-06 15:09:41,198 - DEBUG - https://huggingface.co:443 "GET /api/models/BAAI/bge-large-en HTTP/1.1" 200 147009
2025-02-06 15:09:41,455 - INFO - Embedding model initialized successfully
2025-02-06 15:09:41,455 - DEBUG - Test embedding dimension: 1024
2025-02-06 15:09:42,082 - DEBUG - connect_tcp.started host='localhost' port=6334 local_address=None timeout=5.0 socket_options=None
2025-02-06 15:09:42,098 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B461F9A360>
2025-02-06 15:09:42,098 - DEBUG - send_request_headers.started request=<Request [b'GET']>
2025-02-06 15:09:42,099 - DEBUG - send_request_headers.complete
2025-02-06 15:09:42,100 - DEBUG - send_request_body.started request=<Request [b'GET']>
2025-02-06 15:09:42,101 - DEBUG - send_request_body.complete
2025-02-06 15:09:42,101 - DEBUG - receive_response_headers.started request=<Request [b'GET']>
2025-02-06 15:09:42,103 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'zstd'), (b'date', b'Thu, 06 Feb 2025 09:39:42 GMT')])
2025-02-06 15:09:42,104 - INFO - HTTP Request: GET http://localhost:6334/ "HTTP/1.1 200 OK"
2025-02-06 15:09:42,105 - DEBUG - receive_response_body.started request=<Request [b'GET']>
2025-02-06 15:09:42,105 - DEBUG - receive_response_body.complete
2025-02-06 15:09:42,105 - DEBUG - response_closed.started
2025-02-06 15:09:42,105 - DEBUG - response_closed.complete
2025-02-06 15:09:42,105 - DEBUG - close.started
2025-02-06 15:09:42,106 - DEBUG - close.complete
2025-02-06 15:09:42,106 - WARNING - Could not retrieve cluster info: 'QdrantClient' object has no attribute 'cluster_info'
2025-02-06 15:09:42,119 - INFO - Use pytorch device_name: cpu
2025-02-06 15:09:42,119 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-02-06 15:09:42,356 - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json HTTP/1.1" 200 0
2025-02-06 15:09:42,597 - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json HTTP/1.1" 200 0
2025-02-06 15:09:42,846 - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 200 0
2025-02-06 15:09:43,091 - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json HTTP/1.1" 200 0
2025-02-06 15:09:43,339 - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json HTTP/1.1" 200 0
2025-02-06 15:09:43,669 - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/adapter_config.json HTTP/1.1" 404 0
2025-02-06 15:09:43,915 - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 200 0
2025-02-06 15:09:44,198 - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2025-02-06 15:09:44,483 - DEBUG - https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/revision/main HTTP/1.1" 200 6820
2025-02-06 15:09:44,785 - DEBUG - https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2 HTTP/1.1" 200 6820
2025-02-06 15:10:25,038 - ERROR - Error creating ingestion log table: connection to server at "drug-data-analysis_a04f6f-postgres-1" (13.248.169.48), port 5432 failed: Connection timed out (0x0000274C/10060)
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "drug-data-analysis_a04f6f-postgres-1" (76.223.54.146), port 5432 failed: server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.

2025-02-06 15:10:25,039 - ERROR - Error during data ingestion: connection to server at "drug-data-analysis_a04f6f-postgres-1" (13.248.169.48), port 5432 failed: Connection timed out (0x0000274C/10060)
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "drug-data-analysis_a04f6f-postgres-1" (76.223.54.146), port 5432 failed: server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.

2025-02-06 15:20:03,287 - INFO - Use pytorch device_name: cpu
2025-02-06 15:20:03,288 - INFO - Load pretrained SentenceTransformer: BAAI/bge-large-en
2025-02-06 15:20:03,291 - DEBUG - Starting new HTTPS connection (1): huggingface.co:443
2025-02-06 15:20:03,621 - DEBUG - https://huggingface.co:443 "HEAD /BAAI/bge-large-en/resolve/main/modules.json HTTP/1.1" 200 0
2025-02-06 15:20:03,874 - DEBUG - https://huggingface.co:443 "HEAD /BAAI/bge-large-en/resolve/main/config_sentence_transformers.json HTTP/1.1" 200 0
2025-02-06 15:20:04,131 - DEBUG - https://huggingface.co:443 "HEAD /BAAI/bge-large-en/resolve/main/README.md HTTP/1.1" 200 0
2025-02-06 15:20:04,396 - DEBUG - https://huggingface.co:443 "HEAD /BAAI/bge-large-en/resolve/main/modules.json HTTP/1.1" 200 0
2025-02-06 15:20:04,660 - DEBUG - https://huggingface.co:443 "HEAD /BAAI/bge-large-en/resolve/main/sentence_bert_config.json HTTP/1.1" 200 0
2025-02-06 15:20:04,924 - DEBUG - https://huggingface.co:443 "HEAD /BAAI/bge-large-en/resolve/main/adapter_config.json HTTP/1.1" 404 0
2025-02-06 15:20:05,214 - DEBUG - https://huggingface.co:443 "HEAD /BAAI/bge-large-en/resolve/main/config.json HTTP/1.1" 200 0
2025-02-06 15:20:05,797 - DEBUG - https://huggingface.co:443 "HEAD /BAAI/bge-large-en/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2025-02-06 15:20:06,103 - DEBUG - https://huggingface.co:443 "GET /api/models/BAAI/bge-large-en/revision/main HTTP/1.1" 200 147009
2025-02-06 15:20:06,433 - DEBUG - https://huggingface.co:443 "GET /api/models/BAAI/bge-large-en HTTP/1.1" 200 147009
2025-02-06 15:20:06,693 - INFO - Embedding model initialized successfully
2025-02-06 15:20:06,693 - DEBUG - Test embedding dimension: 1024
2025-02-06 15:20:07,331 - DEBUG - connect_tcp.started host='localhost' port=6334 local_address=None timeout=5.0 socket_options=None
2025-02-06 15:20:07,352 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002003C1AE390>
2025-02-06 15:20:07,353 - DEBUG - send_request_headers.started request=<Request [b'GET']>
2025-02-06 15:20:07,353 - DEBUG - send_request_headers.complete
2025-02-06 15:20:07,354 - DEBUG - send_request_body.started request=<Request [b'GET']>
2025-02-06 15:20:07,354 - DEBUG - send_request_body.complete
2025-02-06 15:20:07,354 - DEBUG - receive_response_headers.started request=<Request [b'GET']>
2025-02-06 15:20:07,355 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'zstd'), (b'content-type', b'application/json'), (b'date', b'Thu, 06 Feb 2025 09:50:07 GMT')])
2025-02-06 15:20:07,356 - INFO - HTTP Request: GET http://localhost:6334/ "HTTP/1.1 200 OK"
2025-02-06 15:20:07,357 - DEBUG - receive_response_body.started request=<Request [b'GET']>
2025-02-06 15:20:07,357 - DEBUG - receive_response_body.complete
2025-02-06 15:20:07,358 - DEBUG - response_closed.started
2025-02-06 15:20:07,358 - DEBUG - response_closed.complete
2025-02-06 15:20:07,358 - DEBUG - close.started
2025-02-06 15:20:07,359 - DEBUG - close.complete
2025-02-06 15:20:07,359 - WARNING - Could not retrieve cluster info: 'QdrantClient' object has no attribute 'cluster_info'
2025-02-06 15:20:07,371 - INFO - Use pytorch device_name: cpu
2025-02-06 15:20:07,372 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-02-06 15:20:07,624 - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json HTTP/1.1" 200 0
2025-02-06 15:20:07,874 - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json HTTP/1.1" 200 0
2025-02-06 15:20:08,127 - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 200 0
2025-02-06 15:20:08,437 - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json HTTP/1.1" 200 0
2025-02-06 15:20:08,713 - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json HTTP/1.1" 200 0
2025-02-06 15:20:08,955 - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/adapter_config.json HTTP/1.1" 404 0
2025-02-06 15:20:09,207 - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 200 0
2025-02-06 15:20:09,494 - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2025-02-06 15:20:09,784 - DEBUG - https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/revision/main HTTP/1.1" 200 6820
2025-02-06 15:20:10,104 - DEBUG - https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2 HTTP/1.1" 200 6820
2025-02-06 15:20:52,202 - ERROR - Error creating ingestion log table: connection to server at "drug-data-analysis_a04f6f-postgres-1" (13.248.169.48), port 5432 failed: Connection timed out (0x0000274C/10060)
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "drug-data-analysis_a04f6f-postgres-1" (76.223.54.146), port 5432 failed: Connection timed out (0x0000274C/10060)
	Is the server running on that host and accepting TCP/IP connections?

2025-02-06 15:20:52,204 - ERROR - Error during data ingestion: connection to server at "drug-data-analysis_a04f6f-postgres-1" (13.248.169.48), port 5432 failed: Connection timed out (0x0000274C/10060)
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "drug-data-analysis_a04f6f-postgres-1" (76.223.54.146), port 5432 failed: Connection timed out (0x0000274C/10060)
	Is the server running on that host and accepting TCP/IP connections?

2025-02-06 15:43:20,551 - INFO - Use pytorch device_name: cpu
2025-02-06 15:43:20,552 - INFO - Load pretrained SentenceTransformer: BAAI/bge-large-en
2025-02-06 15:43:20,554 - DEBUG - Starting new HTTPS connection (1): huggingface.co:443
2025-02-06 15:43:20,893 - DEBUG - https://huggingface.co:443 "HEAD /BAAI/bge-large-en/resolve/main/modules.json HTTP/1.1" 200 0
2025-02-06 15:43:21,148 - DEBUG - https://huggingface.co:443 "HEAD /BAAI/bge-large-en/resolve/main/config_sentence_transformers.json HTTP/1.1" 200 0
2025-02-06 15:43:21,390 - DEBUG - https://huggingface.co:443 "HEAD /BAAI/bge-large-en/resolve/main/README.md HTTP/1.1" 200 0
2025-02-06 15:43:21,634 - DEBUG - https://huggingface.co:443 "HEAD /BAAI/bge-large-en/resolve/main/modules.json HTTP/1.1" 200 0
2025-02-06 15:43:21,877 - DEBUG - https://huggingface.co:443 "HEAD /BAAI/bge-large-en/resolve/main/sentence_bert_config.json HTTP/1.1" 200 0
2025-02-06 15:43:22,117 - DEBUG - https://huggingface.co:443 "HEAD /BAAI/bge-large-en/resolve/main/adapter_config.json HTTP/1.1" 404 0
2025-02-06 15:43:22,361 - DEBUG - https://huggingface.co:443 "HEAD /BAAI/bge-large-en/resolve/main/config.json HTTP/1.1" 200 0
2025-02-06 15:43:22,945 - DEBUG - https://huggingface.co:443 "HEAD /BAAI/bge-large-en/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2025-02-06 15:43:23,649 - DEBUG - https://huggingface.co:443 "GET /api/models/BAAI/bge-large-en/revision/main HTTP/1.1" 200 147009
2025-02-06 15:43:24,116 - DEBUG - https://huggingface.co:443 "GET /api/models/BAAI/bge-large-en HTTP/1.1" 200 147009
2025-02-06 15:43:24,591 - INFO - Embedding model initialized successfully
2025-02-06 15:43:24,592 - DEBUG - Test embedding dimension: 1024
2025-02-06 15:43:25,308 - DEBUG - connect_tcp.started host='localhost' port=6334 local_address=None timeout=5.0 socket_options=None
2025-02-06 15:43:25,310 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001DD3658E2A0>
2025-02-06 15:43:25,310 - DEBUG - send_request_headers.started request=<Request [b'GET']>
2025-02-06 15:43:25,312 - DEBUG - send_request_headers.complete
2025-02-06 15:43:25,312 - DEBUG - send_request_body.started request=<Request [b'GET']>
2025-02-06 15:43:25,312 - DEBUG - send_request_body.complete
2025-02-06 15:43:25,313 - DEBUG - receive_response_headers.started request=<Request [b'GET']>
2025-02-06 15:43:25,313 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'zstd'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'date', b'Thu, 06 Feb 2025 10:13:24 GMT')])
2025-02-06 15:43:25,314 - INFO - HTTP Request: GET http://localhost:6334/ "HTTP/1.1 200 OK"
2025-02-06 15:43:25,315 - DEBUG - receive_response_body.started request=<Request [b'GET']>
2025-02-06 15:43:25,315 - DEBUG - receive_response_body.complete
2025-02-06 15:43:25,315 - DEBUG - response_closed.started
2025-02-06 15:43:25,315 - DEBUG - response_closed.complete
2025-02-06 15:43:25,316 - DEBUG - close.started
2025-02-06 15:43:25,316 - DEBUG - close.complete
2025-02-06 15:43:25,317 - WARNING - Could not retrieve cluster info: 'QdrantClient' object has no attribute 'cluster_info'
2025-02-06 15:43:25,330 - INFO - Use pytorch device_name: cpu
2025-02-06 15:43:25,330 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-02-06 15:43:25,570 - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json HTTP/1.1" 200 0
2025-02-06 15:43:25,835 - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json HTTP/1.1" 200 0
2025-02-06 15:43:26,072 - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 200 0
2025-02-06 15:43:26,321 - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json HTTP/1.1" 200 0
2025-02-06 15:43:26,630 - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json HTTP/1.1" 200 0
2025-02-06 15:43:26,868 - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/adapter_config.json HTTP/1.1" 404 0
2025-02-06 15:43:27,102 - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 200 0
2025-02-06 15:43:27,419 - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2025-02-06 15:43:27,706 - DEBUG - https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/revision/main HTTP/1.1" 200 6820
2025-02-06 15:43:27,953 - DEBUG - https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2 HTTP/1.1" 200 6820
2025-02-06 15:44:10,028 - ERROR - Error creating ingestion log table: connection to server at "drug-data-analysis_a04f6f-postgres-1" (13.248.169.48), port 5432 failed: Connection timed out (0x0000274C/10060)
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "drug-data-analysis_a04f6f-postgres-1" (76.223.54.146), port 5432 failed: Connection timed out (0x0000274C/10060)
	Is the server running on that host and accepting TCP/IP connections?

2025-02-06 15:44:10,029 - ERROR - Error during data ingestion: connection to server at "drug-data-analysis_a04f6f-postgres-1" (13.248.169.48), port 5432 failed: Connection timed out (0x0000274C/10060)
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "drug-data-analysis_a04f6f-postgres-1" (76.223.54.146), port 5432 failed: Connection timed out (0x0000274C/10060)
	Is the server running on that host and accepting TCP/IP connections?

